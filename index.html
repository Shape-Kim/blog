<<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<title>SFNet: Learning Object-aware Semantic Flow</title>
  <meta name="title" content="SFNet: Learning Object-aware Semantic Flow">
  <meta name="description" content="SFNet: Learning Object-aware Semantic Flow">
	<meta name="author" content="SLV-lab">

	<link href="./SFNet_files/bootstrap.min.css" rel="stylesheet">
    <link href="./SFNet_files/style.css" rel="stylesheet">

</head>

  <body>

    <div class="container">
      <div class="header">
        <h3> <center> <b>SFNet: Learning Object-aware Semantic Flow</b> </center> </h3>
        <h4 style="color: #517CB9; font-size: 20px"> <center> <a href="http://cvpr2019.thecvf.com/"><b>*CVPR-2019 (Short-Oral)*</b></a> </center></center></h4>
      </div>

      <center>
        <img src="./SFNet_files/teaser.png" style="max-width:100%;">
      </center>

      <div class="row">
      	<h3>Authors</h3>
      	<div style="font-size: 16px">
      	<ul>
            <li>Junghyup Lee*</li>
            <li><a href="https://github.com/shape-kim">Dohyung Kim*</a></li>
            <li><a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a></li>
            <li><a href="https://bsham.github.io/">Bumsub Ham</a></li>
      	</ul>
      	</div>
      	<p style="text-align: justify;">* Both authors contributed equally to this work</p>

      </div>

      <div class="row">
        <h3>Abstract</h3>
        <p style="text-align: justify;">
        We address the problem of semantic correspondence, that is, establishing a dense flow field between images depicting different instances of the same object or scene category. We propose to use images annotated with binary foreground masks and subjected to synthetic geometric deformations to train a convolutional neural network (CNN) for this task. Using these masks as part of the supervisory signal offers a good compromise between semantic flow methods, where the amount of training data is limited by the cost of manually selecting point correspondences, and semantic alignment ones, where the regression of a single global geometric transformation between images may be sensitive to image-specific details such as background clutter. We propose a new CNN architecture, dubbed SFNet, which implements this idea. It leverages a new and differentiable version of the argmax function for end-to-end training, with a loss that combines mask and flow consistency with smoothness terms. Experimental results demonstrate the effectiveness of our approach, which significantly outperforms the state of the art on standard benchmarks.  
        </p>
      </div>
      <div class="row">
      	<h3>Overview of our architecture</h3>
      	<center>
        <img src="./SFNet_files/method.png" style="max-width:90%;">
      	</center>
      </div>

      <div class="row">
        <h3>Paper</h3>
	<p>
     </p><table>
  <tbody><tr></tr>
  <tr><td>
    <a href="https://arxiv.org/abs/1712.06861"><img style="box-shadow: 5px 5px 2px #888888; margin: 10px" src="./SFNet_files/thb.png" width="150px"></a>
  </td>
  <td></td>
  <td>
    I. Rocco, R. ArandjeloviÄ‡ and J. Sivic<br>
    <b>End-to-end weakly-supervised semantic alignment</b> <br>
    In <i>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2018 <br>
    [<a href="https://arxiv.org/abs/1712.06861">Paper on arXiv</a>]
</td></tr></tbody></table>
     
      <h4>BibTeX</h4>
     <pre><tt>@InProceedings{Rocco18,
        author       = "Rocco, I. and Arandjelovi\'c, R. and Sivic, J.",
        title        = "End-to-end weakly-supervised semantic alignment",
        booktitle    = "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
        year         = "2018",
        }</tt></pre>

      </div>
      <div class="row">

        <h3>Code</h3>
        <p> <a href="https://github.com/ignacio-rocco/weakalign"> Training/testing code (PyTorch) </a>
          </p>
      </div>

      <div class="row">
        <h3>See also</h3>
  <ul>
  <li><a href="http://www.di.ens.fr/willow/research/cnngeometric/">Convolutional neural network architecture for geometric matching
</a>
  </li></ul>
      </div>
      
      
      <div class="row">
        <h3>Acknowledgements</h3>
        <p>
        This work has been partly supported by ERC grant LEAP (no. 336845), the Inria CityLab IPL, CIFAR Learning in Machines &amp; Brains program and ESIF, OP Research, development and education Project IMPACT No. CZ.02.1.01/0.0/0.0/15 003/0000468.
		</p>
      </div>

      <div class="row">
        <h3>Copyright Notice</h3>
        <p>The documents contained in these directories are included by the contributing authors as a means to ensure timely dissemination of scholarly and technical work on a non-commercial basis. Copyright and all rights therein are maintained by the authors or by other copyright holders, notwithstanding that they have offered their works here electronically. It is understood that all persons copying this information will adhere to the terms and constraints invoked by each author's copyright.</p>
      </div>

    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
  
